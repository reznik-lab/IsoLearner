{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IsoLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import isotopolouge_imputer as imputer\n",
    "import visualization as vis\n",
    "import importlib\n",
    "import IsoLearner\n",
    "importlib.reload(imputer)\n",
    "importlib.reload(vis)\n",
    "importlib.reload(IsoLearner)\n",
    "import numpy as np\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# /Users/bisramr/tensorflow-metal/bin/python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing IsoLearner\n",
      "Generating List of valid metabolites from Moran's I calculations ============> Valid Metabolites Calculated\n",
      "Cleaning data ========================> The dataset has been checked for inconsistencies\n",
      "Inconsistencies found: 10 metabolites, 301 isotopolouges\n",
      "File 0: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-ND-M1-FML-ioncounts-ranks.csv || 248 to drop || 248 dropped\n",
      "File 1: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-ND-M2-FML-ioncounts-ranks.csv || 248 to drop || 248 dropped\n",
      "File 2: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-ND-M3-FML-ioncounts-ranks.csv || 248 to drop || 248 dropped\n",
      "File 3: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-KD-M1-FML-ioncounts-ranks.csv || 238 to drop || 238 dropped\n",
      "File 4: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-KD-M2-FML-ioncounts-ranks.csv || 238 to drop || 238 dropped\n",
      "File 5: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-KD-M3-FML-ioncounts-ranks.csv || 238 to drop || 238 dropped\n",
      "Ion-Data is all consistent! Time to train a model!\n",
      "\n",
      "File 0: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-ND-M1-FML-isotopolouges-ranks.csv || 2142 to drop || 2142 dropped\n",
      "File 1: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-ND-M2-FML-isotopolouges-ranks.csv || 2154 to drop || 2154 dropped\n",
      "File 2: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-ND-M3-FML-isotopolouges-ranks.csv || 2126 to drop || 2126 dropped\n",
      "File 3: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-KD-M1-FML-isotopolouges-ranks.csv || 1883 to drop || 1883 dropped\n",
      "File 4: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-KD-M2-FML-isotopolouges-ranks.csv || 1895 to drop || 1895 dropped\n",
      "File 5: /Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data/brain-m0-no-log/Brain-3HB/B3HB-KD-M3-FML-isotopolouges-ranks.csv || 1897 to drop || 1897 dropped\n",
      "Iso-Data is all consistent! Time to train a model!\n",
      "\n",
      "Reading in coord data\n"
     ]
    }
   ],
   "source": [
    "Brain_3HB_IsoLearner = IsoLearner.IsoLearner(absolute_data_path = \"/Users/bisramr/MATLAB/Projects/Isoscope_Matlab_V/generated-data\",\n",
    "                                            relative_data_path = \"brain-m0-no-log/Brain-3HB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE ARE IN THIS FUNCTION\n",
      "Empty directory './saved-weights/cross-validation-3HB' has been deleted.\n",
      "Creating checkpoint directory\n",
      "Training with replicate 0 heldout. # samples = 84722\n",
      "HI\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 4s 5ms/step - loss: 50.3205 - mse: 2.0317 - mae: 1.1188 - val_loss: 43.9339 - val_mse: 1.0286 - val_mae: 0.8076\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 39.5673 - mse: 1.3063 - mae: 0.8787 - val_loss: 34.6964 - val_mse: 0.8000 - val_mae: 0.6922\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 30.7463 - mse: 0.6839 - mae: 0.6459 - val_loss: 26.8704 - val_mse: 0.4398 - val_mae: 0.5383\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 23.6939 - mse: 0.4482 - mae: 0.5393 - val_loss: 20.5810 - val_mse: 0.3312 - val_mae: 0.4767\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 18.0171 - mse: 0.3556 - mae: 0.4873 - val_loss: 15.5279 - val_mse: 0.2851 - val_mae: 0.4446\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 13.4791 - mse: 0.3017 - mae: 0.4520 - val_loss: 11.5108 - val_mse: 0.2529 - val_mae: 0.4192\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 9.8988 - mse: 0.2623 - mae: 0.4229 - val_loss: 8.3662 - val_mse: 0.2278 - val_mae: 0.3972\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 7.1201 - mse: 0.2314 - mae: 0.3975 - val_loss: 5.9485 - val_mse: 0.2066 - val_mae: 0.3772\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 5.0049 - mse: 0.2058 - mae: 0.3746 - val_loss: 4.1285 - val_mse: 0.1878 - val_mae: 0.3584\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 3.4314 - mse: 0.1843 - mae: 0.3539 - val_loss: 2.7921 - val_mse: 0.1709 - val_mae: 0.3410\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.2911 - mse: 0.1659 - mae: 0.3353 - val_loss: 1.8381 - val_mse: 0.1558 - val_mae: 0.3251\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 1.4888 - mse: 0.1500 - mae: 0.3186 - val_loss: 1.1780 - val_mse: 0.1423 - val_mae: 0.3106\n",
      "Epoch 13/100\n",
      "271/530 [==============>...............] - ETA: 1s - loss: 1.0498 - mse: 0.1392 - mae: 0.3070\n",
      "Epoch 13: saving model to ./saved-weights/cross-validation-3HB/holdout-0/checkpoint\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.9427 - mse: 0.1359 - mae: 0.3034 - val_loss: 0.7380 - val_mse: 0.1300 - val_mae: 0.2971\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.5875 - mse: 0.1244 - mae: 0.2905 - val_loss: 0.4588 - val_mse: 0.1197 - val_mae: 0.2853\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.3666 - mse: 0.1149 - mae: 0.2795 - val_loss: 0.2890 - val_mse: 0.1105 - val_mae: 0.2744\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.2364 - mse: 0.1067 - mae: 0.2697 - val_loss: 0.1935 - val_mse: 0.1035 - val_mae: 0.2660\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.1654 - mse: 0.1001 - mae: 0.2616 - val_loss: 0.1433 - val_mse: 0.0972 - val_mae: 0.2583\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.1299 - mse: 0.0948 - mae: 0.2551 - val_loss: 0.1196 - val_mse: 0.0927 - val_mae: 0.2528\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.1130 - mse: 0.0905 - mae: 0.2498 - val_loss: 0.1078 - val_mse: 0.0886 - val_mae: 0.2473\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.1044 - mse: 0.0870 - mae: 0.2455 - val_loss: 0.1017 - val_mse: 0.0858 - val_mae: 0.2441\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0991 - mse: 0.0841 - mae: 0.2418 - val_loss: 0.0975 - val_mse: 0.0833 - val_mae: 0.2407\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0951 - mse: 0.0816 - mae: 0.2387 - val_loss: 0.0934 - val_mse: 0.0806 - val_mae: 0.2373\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0918 - mse: 0.0796 - mae: 0.2361 - val_loss: 0.0897 - val_mse: 0.0781 - val_mae: 0.2335\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0888 - mse: 0.0778 - mae: 0.2337 - val_loss: 0.0871 - val_mse: 0.0767 - val_mae: 0.2319\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0863 - mse: 0.0764 - mae: 0.2318 - val_loss: 0.0846 - val_mse: 0.0753 - val_mae: 0.2300\n",
      "Epoch 26/100\n",
      " 23/530 [>.............................] - ETA: 2s - loss: 0.0853 - mse: 0.0760 - mae: 0.2315\n",
      "Epoch 26: saving model to ./saved-weights/cross-validation-3HB/holdout-0/checkpoint\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0841 - mse: 0.0752 - mae: 0.2302 - val_loss: 0.0832 - val_mse: 0.0748 - val_mae: 0.2296\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0821 - mse: 0.0741 - mae: 0.2288 - val_loss: 0.0812 - val_mse: 0.0736 - val_mae: 0.2279\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0804 - mse: 0.0733 - mae: 0.2276 - val_loss: 0.0798 - val_mse: 0.0730 - val_mae: 0.2273\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0790 - mse: 0.0726 - mae: 0.2266 - val_loss: 0.0782 - val_mse: 0.0721 - val_mae: 0.2256\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0778 - mse: 0.0720 - mae: 0.2258 - val_loss: 0.0771 - val_mse: 0.0716 - val_mae: 0.2255\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0767 - mse: 0.0715 - mae: 0.2251 - val_loss: 0.0762 - val_mse: 0.0712 - val_mae: 0.2243\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0758 - mse: 0.0711 - mae: 0.2245 - val_loss: 0.0753 - val_mse: 0.0708 - val_mae: 0.2237\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0751 - mse: 0.0708 - mae: 0.2240 - val_loss: 0.0745 - val_mse: 0.0704 - val_mae: 0.2232\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0745 - mse: 0.0705 - mae: 0.2237 - val_loss: 0.0741 - val_mse: 0.0702 - val_mae: 0.2230\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0740 - mse: 0.0703 - mae: 0.2233 - val_loss: 0.0738 - val_mse: 0.0702 - val_mae: 0.2232\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0737 - mse: 0.0702 - mae: 0.2231 - val_loss: 0.0733 - val_mse: 0.0700 - val_mae: 0.2226\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0733 - mse: 0.0701 - mae: 0.2228 - val_loss: 0.0730 - val_mse: 0.0698 - val_mae: 0.2222\n",
      "Epoch 38/100\n",
      "306/530 [================>.............] - ETA: 1s - loss: 0.0731 - mse: 0.0699 - mae: 0.2226\n",
      "Epoch 38: saving model to ./saved-weights/cross-validation-3HB/holdout-0/checkpoint\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0731 - mse: 0.0700 - mae: 0.2226 - val_loss: 0.0728 - val_mse: 0.0698 - val_mae: 0.2219\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0729 - mse: 0.0699 - mae: 0.2225 - val_loss: 0.0727 - val_mse: 0.0697 - val_mae: 0.2219\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0728 - mse: 0.0698 - mae: 0.2223 - val_loss: 0.0728 - val_mse: 0.0699 - val_mae: 0.2225\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0726 - mse: 0.0698 - mae: 0.2222 - val_loss: 0.0723 - val_mse: 0.0695 - val_mae: 0.2211\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0725 - mse: 0.0697 - mae: 0.2221 - val_loss: 0.0725 - val_mse: 0.0696 - val_mae: 0.2220\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0725 - mse: 0.0697 - mae: 0.2220 - val_loss: 0.0723 - val_mse: 0.0695 - val_mae: 0.2215\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0724 - mse: 0.0696 - mae: 0.2219 - val_loss: 0.0724 - val_mse: 0.0696 - val_mae: 0.2221\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0723 - mse: 0.0696 - mae: 0.2218 - val_loss: 0.0720 - val_mse: 0.0693 - val_mae: 0.2208\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0723 - mse: 0.0696 - mae: 0.2217 - val_loss: 0.0721 - val_mse: 0.0694 - val_mae: 0.2213\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0722 - mse: 0.0696 - mae: 0.2216 - val_loss: 0.0721 - val_mse: 0.0694 - val_mae: 0.2215\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0722 - mse: 0.0695 - mae: 0.2215 - val_loss: 0.0721 - val_mse: 0.0695 - val_mae: 0.2218\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0721 - mse: 0.0695 - mae: 0.2215 - val_loss: 0.0720 - val_mse: 0.0694 - val_mae: 0.2212\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0721 - mse: 0.0695 - mae: 0.2214 - val_loss: 0.0721 - val_mse: 0.0696 - val_mae: 0.2220\n",
      "Epoch 51/100\n",
      " 59/530 [==>...........................] - ETA: 2s - loss: 0.0720 - mse: 0.0695 - mae: 0.2213\n",
      "Epoch 51: saving model to ./saved-weights/cross-validation-3HB/holdout-0/checkpoint\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0720 - mse: 0.0695 - mae: 0.2213 - val_loss: 0.0720 - val_mse: 0.0695 - val_mae: 0.2216\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0720 - mse: 0.0694 - mae: 0.2212 - val_loss: 0.0718 - val_mse: 0.0693 - val_mae: 0.2210\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0719 - mse: 0.0694 - mae: 0.2211 - val_loss: 0.0720 - val_mse: 0.0695 - val_mae: 0.2216\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0719 - mse: 0.0694 - mae: 0.2211 - val_loss: 0.0716 - val_mse: 0.0692 - val_mae: 0.2203\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0718 - mse: 0.0694 - mae: 0.2210 - val_loss: 0.0716 - val_mse: 0.0692 - val_mae: 0.2203\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0718 - mse: 0.0694 - mae: 0.2210 - val_loss: 0.0717 - val_mse: 0.0693 - val_mae: 0.2208\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0717 - mse: 0.0694 - mae: 0.2209 - val_loss: 0.0715 - val_mse: 0.0691 - val_mae: 0.2203\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0717 - mse: 0.0693 - mae: 0.2209 - val_loss: 0.0716 - val_mse: 0.0692 - val_mae: 0.2206\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0717 - mse: 0.0693 - mae: 0.2208 - val_loss: 0.0714 - val_mse: 0.0691 - val_mae: 0.2197\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0716 - mse: 0.0693 - mae: 0.2208 - val_loss: 0.0714 - val_mse: 0.0691 - val_mae: 0.2202\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0716 - mse: 0.0693 - mae: 0.2207 - val_loss: 0.0714 - val_mse: 0.0691 - val_mae: 0.2203\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0716 - mse: 0.0693 - mae: 0.2207 - val_loss: 0.0714 - val_mse: 0.0692 - val_mae: 0.2206\n",
      "Epoch 63/100\n",
      "333/530 [=================>............] - ETA: 0s - loss: 0.0715 - mse: 0.0693 - mae: 0.2206\n",
      "Epoch 63: saving model to ./saved-weights/cross-validation-3HB/holdout-0/checkpoint\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0715 - mse: 0.0693 - mae: 0.2206 - val_loss: 0.0714 - val_mse: 0.0692 - val_mae: 0.2204\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0715 - mse: 0.0692 - mae: 0.2206 - val_loss: 0.0712 - val_mse: 0.0690 - val_mae: 0.2197\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0714 - mse: 0.0692 - mae: 0.2205 - val_loss: 0.0713 - val_mse: 0.0691 - val_mae: 0.2204\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0714 - mse: 0.0692 - mae: 0.2205 - val_loss: 0.0712 - val_mse: 0.0690 - val_mae: 0.2198\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0714 - mse: 0.0692 - mae: 0.2204 - val_loss: 0.0711 - val_mse: 0.0690 - val_mae: 0.2195\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0713 - mse: 0.0692 - mae: 0.2204 - val_loss: 0.0715 - val_mse: 0.0694 - val_mae: 0.2206\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0713 - mse: 0.0692 - mae: 0.2203 - val_loss: 0.0711 - val_mse: 0.0690 - val_mae: 0.2198\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0713 - mse: 0.0692 - mae: 0.2203 - val_loss: 0.0712 - val_mse: 0.0691 - val_mae: 0.2203\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0713 - mse: 0.0692 - mae: 0.2203 - val_loss: 0.0711 - val_mse: 0.0690 - val_mae: 0.2197\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0712 - mse: 0.0692 - mae: 0.2202 - val_loss: 0.0711 - val_mse: 0.0690 - val_mae: 0.2200\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0712 - mse: 0.0691 - mae: 0.2202 - val_loss: 0.0711 - val_mse: 0.0691 - val_mae: 0.2202\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0712 - mse: 0.0691 - mae: 0.2202 - val_loss: 0.0711 - val_mse: 0.0691 - val_mae: 0.2202\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0711 - mse: 0.0691 - mae: 0.2201 - val_loss: 0.0711 - val_mse: 0.0690 - val_mae: 0.2199\n",
      "Epoch 76/100\n",
      " 86/530 [===>..........................] - ETA: 2s - loss: 0.0711 - mse: 0.0691 - mae: 0.2201\n",
      "Epoch 76: saving model to ./saved-weights/cross-validation-3HB/holdout-0/checkpoint\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0711 - mse: 0.0691 - mae: 0.2201 - val_loss: 0.0710 - val_mse: 0.0690 - val_mae: 0.2196\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0711 - mse: 0.0691 - mae: 0.2201 - val_loss: 0.0710 - val_mse: 0.0690 - val_mae: 0.2199\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0711 - mse: 0.0691 - mae: 0.2200 - val_loss: 0.0708 - val_mse: 0.0689 - val_mae: 0.2193\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0710 - mse: 0.0691 - mae: 0.2200 - val_loss: 0.0708 - val_mse: 0.0689 - val_mae: 0.2193\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0710 - mse: 0.0691 - mae: 0.2200 - val_loss: 0.0709 - val_mse: 0.0689 - val_mae: 0.2195\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0710 - mse: 0.0691 - mae: 0.2200 - val_loss: 0.0708 - val_mse: 0.0689 - val_mae: 0.2193\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0710 - mse: 0.0691 - mae: 0.2199 - val_loss: 0.0708 - val_mse: 0.0689 - val_mae: 0.2197\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0710 - mse: 0.0691 - mae: 0.2200 - val_loss: 0.0708 - val_mse: 0.0690 - val_mae: 0.2195\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0709 - mse: 0.0691 - mae: 0.2199 - val_loss: 0.0708 - val_mse: 0.0690 - val_mae: 0.2198\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0709 - mse: 0.0691 - mae: 0.2199 - val_loss: 0.0708 - val_mse: 0.0690 - val_mae: 0.2197\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0709 - mse: 0.0690 - mae: 0.2198 - val_loss: 0.0707 - val_mse: 0.0689 - val_mae: 0.2194\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0709 - mse: 0.0690 - mae: 0.2198 - val_loss: 0.0707 - val_mse: 0.0689 - val_mae: 0.2194\n",
      "Epoch 88/100\n",
      "362/530 [===================>..........] - ETA: 0s - loss: 0.0709 - mse: 0.0691 - mae: 0.2198\n",
      "Epoch 88: saving model to ./saved-weights/cross-validation-3HB/holdout-0/checkpoint\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0708 - mse: 0.0690 - mae: 0.2198 - val_loss: 0.0706 - val_mse: 0.0689 - val_mae: 0.2189\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0708 - mse: 0.0690 - mae: 0.2198 - val_loss: 0.0707 - val_mse: 0.0689 - val_mae: 0.2195\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0708 - mse: 0.0690 - mae: 0.2197 - val_loss: 0.0706 - val_mse: 0.0689 - val_mae: 0.2192\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.0708 - mse: 0.0690 - mae: 0.2197 - val_loss: 0.0706 - val_mse: 0.0689 - val_mae: 0.2193\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0707 - mse: 0.0690 - mae: 0.2197 - val_loss: 0.0707 - val_mse: 0.0689 - val_mae: 0.2196\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0707 - mse: 0.0690 - mae: 0.2197 - val_loss: 0.0707 - val_mse: 0.0690 - val_mae: 0.2196\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0707 - mse: 0.0690 - mae: 0.2196 - val_loss: 0.0706 - val_mse: 0.0689 - val_mae: 0.2193\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0707 - mse: 0.0690 - mae: 0.2196 - val_loss: 0.0706 - val_mse: 0.0689 - val_mae: 0.2193\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0707 - mse: 0.0690 - mae: 0.2196 - val_loss: 0.0705 - val_mse: 0.0688 - val_mae: 0.2192\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0707 - mse: 0.0690 - mae: 0.2195 - val_loss: 0.0704 - val_mse: 0.0688 - val_mae: 0.2187\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0706 - mse: 0.0690 - mae: 0.2195 - val_loss: 0.0705 - val_mse: 0.0688 - val_mae: 0.2192\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0706 - mse: 0.0690 - mae: 0.2195 - val_loss: 0.0706 - val_mse: 0.0689 - val_mae: 0.2192\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0706 - mse: 0.0689 - mae: 0.2195 - val_loss: 0.0706 - val_mse: 0.0689 - val_mae: 0.2194\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAE8CAYAAABDzD21AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+8klEQVR4nO3deVxU1f8/8NedgRn2RZFNERQXcANCIbTSEgM1cyut/CVaZiqlRovyMUHzm1i5UGmaltjiJ7fSj7krYhaSOy6JuCGQMiAhIDszc35/4Ny8sjgMy50L7+fjcR8y5547931n4O259557DscYYyCEEAmTiR0AIYQ0FCUyQojkUSIjhEgeJTJCiORRIiOESB4lMkKI5FEiI4RIHiUyQojkUSIjhEgeJbIWbNCgQRg0aNAj6x05cgQcx+HIkSNNHpOU1PS5TJo0CR4eHqLFRGpGiUxkGzZsAMdxOHXqVI3rBw0ahF69ejVzVI2vpKQECxYsoGT5CF999RU2bNjQJO+dkpKC0NBQWFlZoU2bNnj11Vdx586dJtlXczMROwDSOpSUlGDhwoUAoFcr0VitW7cOWq22yd7/q6++goODAyZNmtSo7/v333/jqaeegq2tLRYvXoyioiIsXboUFy5cwIkTJ6BQKBp1f82NEhmRvOLiYlhaWjbLvkxNTZtlP41t8eLFKC4uxunTp9GxY0cAQEBAAIYMGYINGzZg6tSpIkfYMHRqKUFqtRqLFi2Cp6cnlEolPDw88J///Afl5eWP3Pbvv//GqFGjYGlpCUdHR7zzzju1brd161b4+/vD3NwcDg4O+H//7//h1q1bgjq1XYd78FrSzZs30a5dOwDAwoULwXEcOI7DggULAACVlZW4fPkysrKyHhn/pEmTYGVlhevXr2PYsGGwtrbGhAkTAABarRaxsbHo2bMnzMzM4OTkhDfffBN3794VvIeHhweee+45HDhwAL6+vjAzM0OPHj3wyy+/6LX/h6+RabVafP755+jduzfMzMzQrl07hIaGCi4XxMXF4ZlnnoGjoyOUSiV69OiB1atXV4vrr7/+wm+//cZ/Rg9+tvn5+Zg9ezbc3NygVCrRpUsXfPLJJ3q1EH/++Wc899xzfBIDgODgYHTr1g1btmx55PbGjlpkRqKgoAC5ubnVyisrK6uVTZkyBd999x1eeOEFvPvuuzh+/DhiYmKQkpKC7du317qP0tJSDB48GBkZGZg5cyZcXV3xww8/4PDhw9XqbtiwAZMnT0a/fv0QExOD7OxsfP7550hMTMTZs2dhZ2en97G1a9cOq1evxvTp0zF69GiMGTMGANCnTx8AwK1bt+Dt7Y2wsDC9rg+p1WqEhITgiSeewNKlS2FhYQEAePPNN/m4Z86cibS0NKxcuRJnz55FYmKioDV19epVjB8/HtOmTUNYWBji4uLw4osvYt++fRgyZIjexwYAr7/+OjZs2IChQ4diypQpUKvV+P333/Hnn3+ib9++AIDVq1ejZ8+eeP7552FiYoJff/0VM2bMgFarRXh4OAAgNjYWb7/9NqysrDBv3jwAgJOTE4CqU/OBAwfi1q1bePPNN9GxY0ccO3YMkZGRyMrKQmxsbK3x3bp1Czk5OXwsDwoICMCePXvqdbxGiRFRxcXFMQB1Lj179uTrJycnMwBsypQpgvd57733GAB2+PBhvmzgwIFs4MCB/OvY2FgGgG3ZsoUvKy4uZl26dGEAWEJCAmOMsYqKCubo6Mh69erFSktL+bq7du1iAFhUVFSt+9AJCwtj7u7u/Os7d+4wACw6Orpa3bS0NAaAhYWFPeLTqnpfAGzu3LmC8t9//50BYBs3bhSU79u3r1q5u7s7A8B+/vlnvqygoIC5uLgwPz8/viwhIUHwudR0XIcPH2YA2MyZM6vFqtVq+Z9LSkqqrQ8JCWGdO3cWlPXs2bPGz3PRokXM0tKSXblyRVA+d+5cJpfLWUZGRrVtdE6ePMkAsO+//77auvfff58BYGVlZbVuLwV0amkkVq1ahYMHD1ZbdK0WHd3/nhEREYLyd999FwCwe/fuWvexZ88euLi44IUXXuDLLCwsql0fOXXqFHJycjBjxgyYmZnx5cOHD4eXl1ed+zCEh4cHGGP1uls3ffp0weutW7fC1tYWQ4YMQW5uLr/4+/vDysoKCQkJgvqurq4YPXo0/9rGxgYTJ07E2bNnoVKp9I7j559/BsdxiI6OrraO4zj+Z3Nzc/5nXet74MCBuHHjBgoKCh65n61bt+LJJ5+Evb294PiCg4Oh0Whw9OjRWrctLS0FACiVymrrdN+vro5U0amlkQgICKix6a/7xdVJT0+HTCZDly5dBPWcnZ1hZ2eH9PT0WveRnp6OLl26CP7AAKB79+7V6tVUDgBeXl74448/Hn1ATcjExAQdOnQQlF29ehUFBQVwdHSscZucnBzB65o+h27dugGouqbn7OysVyzXr1+Hq6sr2rRpU2e9xMREREdHIykpCSUlJYJ1BQUFsLW1rXP7q1ev4vz58/y1xoc9fHwP0iXRmq6FlpWVCepIFSUyiXr4j1AsHMeB1TBaukajabJ9KpVKyGTCkwmtVgtHR0ds3Lixxm1qSwDN4fr16xg8eDC8vLywfPlyuLm5QaFQYM+ePVixYoVeF+u1Wi2GDBmCDz74oMb1uiRcExcXFwCo8WZKVlYW2rRpU2NrTUookUmMu7s7tFotrl69Cm9vb748Ozsb+fn5cHd3r3PbixcvgjEmSISpqanV6unKn3nmGcG61NRUwT7s7e1x48aNavt6uGXY1InX09MThw4dwoABA/RqXVy7dq3a53DlyhUAqFfPfU9PT+zfvx95eXm1tsp+/fVXlJeXY+fOnYK7hg+f7gK1f06enp4oKipCcHCw3rHptG/fHu3ataux0/WJEyfg6+tb7/c0NnSNTGKGDRsGANXuUi1fvhxA1XWsura9ffs2tm3bxpeVlJRg7dq1gnp9+/aFo6Mj1qxZIzgd2bt3L1JSUgT78PT0xOXLlwU9xM+dO4fExETBe+ruLObn51eLqz7dL2ozbtw4aDQaLFq0qNo6tVpdbb+3b98W3OEtLCzE999/D19fX71PKwFg7NixYIzxnX0fpGupyuVywWug6nQyLi6u2jaWlpY1fkbjxo1DUlIS9u/fX21dfn4+1Gr1I+PctWsXMjMz+bL4+HhcuXIFL774Yp3bSoKINxoI+/eu5cmTJ2tcP3DgQMFdS8b+vXM3btw4tmrVKv71qFGjqm374B0w3R1KMzMzNmfOHBYbG8v8/f1Znz59qt2d08UVGBjIYmNjWWRkJLOwsGAeHh7s7t27fL1Lly4xmUzG/Pz82MqVK1lUVBRzdHRkvXv3FtzdY4yxHj16MGdnZ7Zq1Sr2008/sQsXLjDG6n/X0tLSssZ1b775JgPAhg4dylasWMFWrlzJZs2axVxdXdnWrVv5eu7u7qxbt27Mzs6OzZ07l61YsYL17t2byWQytm/fPr6ePnctGWPs1Vdf5ff7+eefsxUrVrAxY8awL7/8kjHG2OXLl5lCoWC9e/dmK1euZEuWLGGenp7Mx8eHAWBpaWn8e82YMYNxHMcWLVrEfvrpJxYfH88Yq/ruHnvsMWZiYsKmTJnCVq9ezZYuXcp/Hnfu3Knzc8vIyGBt27Zlnp6e7IsvvmCLFy9m9vb2rHfv3pK/Y8kYY5TIRGZIIqusrGQLFy5knTp1YqampszNzY1FRkZW+4WsqWtEeno6e/7555mFhQVzcHBgs2bN4rsoPPgHyxhjmzdvZn5+fkypVLI2bdqwCRMmsL///rtajD/++CPr3LkzUygUzNfXl+3fv7/GP/hjx44xf39/plAoBF0xGiuRMcbY2rVrmb+/PzM3N2fW1tasd+/e7IMPPmC3b9/m67i7u7Phw4ez/fv3sz59+jClUsm8vLwEyY4x/ROZWq1mn332GfPy8mIKhYK1a9eODR06lJ0+fZqvs3PnTtanTx9mZmbGPDw82CeffMLWr19fLZGpVCo2fPhwZm1tzQAIvr979+6xyMhI1qVLF6ZQKJiDgwPr378/W7p0KauoqHjkZ3fx4kX27LPPMgsLC2ZnZ8cmTJjAVCrVI7eTAo4xmteStC4eHh7o1asXdu3aJXYopJHQNTJCiORRIiOESB4lMkKI5ImayI4ePYoRI0bA1dUVHMdhx44dj9zmyJEjeOyxx/in/5tqEDrSct28eZOuj7Uwoiay4uJi+Pj4YNWqVXrVT0tLw/Dhw/H0008jOTkZs2fPxpQpU2rsW0MIaT2M5q4lx3HYvn07Ro0aVWudOXPmYPfu3bh48SJf9tJLLyE/Px/79u1rhigJIcZIUo8oJSUlVXtEIyQkBLNnz651m/LyckHvdK1Wi7y8PLRt29ZonlckhPyLMYZ79+7B1dW12jO1tZFUIlOpVPxAczpOTk4oLCxEaWlpjc/YxcTE1Pj4CCHEuGVmZlYb5aQ2kkpkhoiMjBSM3VVQUICOHTsiMzMTNjY2IkYGDBgAXLwI/IJRGLxxCvDcc6LGQ4gxKCwshJubG6ytrfXeRlKJzNnZGdnZ2YKy7Oxs2NjY1DrigVKprHGIEhsbG9ETmS5kBcxho1AAIsdDiDGpz6UfSfUjCwoKQnx8vKDs4MGDCAoKEimihtENIV8BBVDD2PyEEP2ImsiKioqQnJyM5ORkAFXdK5KTk5GRkQGg6rRw4sSJfP1p06bhxo0b+OCDD3D58mV89dVX2LJlC9555x0xwm8wXSKrhCnwiGFYCCG1EzWRnTp1Cn5+fvDz8wNQNQ69n58foqKiAFSNXqlLagDQqVMn7N69GwcPHoSPjw+WLVuGb775BiEhIaLE31C6OVErYUotMkIaQNRrZIMGDapxmGSdmnrtDxo0CGfPnm3CqJqP4NSyhbTIGGNQq9VNOtQ1kTa5XA4TE5NG7f4kqYv9LQ3fInP1AOoxT6SxqqioQFZWVrXJNQh5mIWFBVxcXKDQ/RE0ECUyEfEtsshoYJy4sTSUVqtFWloa5HI5XF1doVAoqMMxqYYxhoqKCty5cwdpaWno2rWr3p1e60KJTET8xf4WcHmsoqICWq0Wbm5u/Pj8hNTE3NwcpqamSE9PR0VFhWDuVENJqvtFS8OfWraARKbTGP+7kpavsX9P6LdORPyp5WefA199JW4whEgYnVqKiD+1zM0HcoxiEBJCJIlaZCIS9COrqBA3GNKoPDw8qs09WpcjR46A47ga57Qkj0aJTESCfmSUyETBcVydy4IFCwx635MnT2Lq1Kl61+/fvz+ysrJga2tr0P701VITJp1aikjQIntgzDTSfB6c3Xzz5s2IiopCamoqX2ZlZcX/zBiDRqOBicmj/2zatWtXrzgUCkW9ZjgnQtQiE1GraZEVF9e+lJXpX7e0VL+69eDs7Mwvtra24DiOf3358mVYW1tj79698Pf3h1KpxB9//IHr169j5MiRcHJygpWVFfr164dDhw4J3vfhU0uO4/DNN99g9OjRsLCwQNeuXbFz505+/cMtpQ0bNsDOzg779++Ht7c3rKysEBoaKki8arUaM2fOhJ2dHdq2bYs5c+YgLCyszlGWH+Xu3buYOHEi7O3tYWFhgaFDh+Lq1av8+vT0dIwYMQL29vawtLREz549sWfPHn7bCRMmoF27djA3N0fXrl0RFxdncCz1QYlMRIKHxltyi8zKqvZl7FhhXUfH2usOHSqs6+FRc71GNnfuXCxZsgQpKSno06cPioqKMGzYMMTHx+Ps2bMIDQ3FiBEjBM8F12ThwoUYN24czp8/j2HDhmHChAnIy8urtX5JSQmWLl2KH374AUePHkVGRgbee+89fv0nn3yCjRs3Ii4uDomJiSgsLNRrAp+6TJo0CadOncLOnTuRlJQExhiGDRuGyvt9hMLDw1FeXo6jR4/iwoUL+OSTT/hW6/z583Hp0iXs3bsXKSkpWL16NRwcHBoUj97EmuJcLAUFBQwAKygoEDsU9tlnjAGMTbTcxlhEhNjhNEhpaSm7dOkSKy0trb4SqH0ZNkxY18Ki9roDBwrrOjjUXM9AcXFxzNbWln+dkJDAALAdO3Y8ctuePXuyL7/8kn/t7u7OVqxYwb8GwD788EP+dVFREQPA9u7dK9jX3bt3+VgAsGvXrvHbrFq1ijk5OfGvnZyc2Geffca/VqvVrGPHjmzkyJG1xvnwfh505coVBoAlJibyZbm5uczc3Jxt2bKFMcZY79692YIFC2p87xEjRrDJkyfXuu8H1fX7YsjfKF0jExF/ajliLLBsbN2VpayoqPZ1crnwdU5O7XUf7kR586bBIdVH3759Ba+LioqwYMEC7N69G1lZWVCr1SgtLX1ki6xPnz78z5aWlrCxsUFOHcdrYWEBT09P/rWLiwtfv6CgANnZ2QgICODXy+Vy+Pv7Q6vV1uv4dFJSUmBiYoLAwEC+rG3btujevTtSUlIAADNnzsT06dNx4MABBAcHY+zYsfxxTZ8+HWPHjsWZM2fw7LPPYtSoUejfv79BsdQXnVqKqCU9olQnS8val4cfT6mr7sOjANdWr9HDF77ne++9h+3bt2Px4sX4/fffkZycjN69e6PiEdc5TXVf+H0cx9WZdGqqz0Se9GzKlCm4ceMGXn31VVy4cAF9+/bFl19+CQAYOnQo0tPT8c477+D27dsYPHiw4FS4KVEiE5HurmVLvs7fEiUmJmLSpEkYPXo0evfuDWdnZ9xsptahjq2tLZycnHDy5Em+TKPR4MyZMwa/p7e3N9RqNY4fP86X/fPPP0hNTUWPHj34Mjc3N0ybNg2//PIL3n33Xaxbt45f165dO4SFheHHH39EbGws1q5da3A89UGnliLiW2S/JQKTvwGa6Q4PaZiuXbvil19+wYgRI8BxHObPn2/w6VxDvP3224iJiUGXLl3g5eWFL7/8Enfv3tVr1JELFy4IJvfgOA4+Pj4YOXIk3njjDXz99dewtrbG3Llz0b59e4wcORIAMHv2bAwdOhTdunXD3bt3kZCQAG9vbwBAVFQU/P390bNnT5SXl2PXrl38uqZGiUxEfD+ywlLg/jUIYvyWL1+O1157Df3794eDgwPmzJmDwsLCZo9jzpw5UKlUmDhxIuRyOaZOnYqQkBDIH77uWIOnnnpK8Foul0OtViMuLg6zZs3Cc889h4qKCjz11FPYs2cPf5qr0WgQHh6Ov//+GzY2NggNDcWKFSsAVPWFi4yMxM2bN2Fubo4nn3wSmzZtavwDr4HRzDTeXAoLC2Fra4uCggLRZ1Hatg148UXgSRzFUd9ZgIRHvi0rK0NaWho6derUKMOykPrTarXw9vbGuHHjsGjRIrHDqVNdvy+G/I1Si0xEgn5kdKGM1FN6ejoOHDiAgQMHory8HCtXrkRaWhpeeeUVsUNrdnSxX0T0iBJpCJlMhg0bNqBfv34YMGAALly4gEOHDjXbdSljQi0yEQkeUaJERurJzc0NiYmJYodhFKhFJqJW84gSIU2MEpmI+H5kMnOguZ5JI6QFokQmIr5F1t4DuHRJ1FgIkTJKZCJqiZOPECIGSmQi4i/2U88LQhqEEpmI+FPLgmIgKAigGboJMQglMhHxp5YaGfDnn3TnkhADUSITkaAfGUCJTARNNfmI7r31GbFV33qkdtQhVkS6RKaFHBrIIKdE1uzqM/kIMV7UIhOR7tQSaJnPWzJW91wiTbnoOxRCXZOPODs7Y9OmTfD29oaZmRm8vLzw1QMzwldUVOCtt96Ci4sLzMzM4O7ujpiYGABVk48AwOjRo8FxHP+6vrRaLT766CN06NABSqUSvr6+2Ldvn14xMMawYMECdOzYEUqlEq6urpg5c6ZBcRg7apGJ6MEBQCthCrMW1iIrKWmSuUD0UlTU8MFiN27ciKioKKxcuRJ+fn44e/Ys3njjDVhaWiIsLAxffPEFdu7ciS1btqBjx47IzMxEZmYmgKp5LR0dHREXF4fQ0FC9htapyeeff45ly5bh66+/hp+fH9avX4/nn38ef/31F7p27VpnDD///DNWrFiBTZs2oWfPnlCpVDh37lzDPhQjRYlMRC29RSZ10dHRWLZsGcaMGQMA6NSpEy5duoSvv/4aYWFhyMjIQNeuXfHEE0+A4zi4u7vz2+rmtbSzs2vQfJVLly7FnDlz8NJLLwGomjkpISEBsbGxWLVqVZ0xZGRkwNnZGcHBwTA1NUXHjh0FY/y3JJTIRCSXAxxXdRpUYdMOEGGU0aZkYVH3vCNNve+GKC4uxvXr1/H666/jjTfe4MvVajU/G/ikSZMwZMgQdO/eHaGhoXjuuefw7LPPNmzHDygsLMTt27cxYMAAQfmAAQP4llVdMbz44ouIjY1F586dERoaimHDhmHEiBF6TTAsNS3viCTG9H5DrPJiKuAmdjSNi+OaZC6QZlF0PwOvW7dOMKsQAP408bHHHkNaWhr27t2LQ4cOYdy4cQgODsa2bduaLc66YnBzc0NqaioOHTqEgwcPYsaMGfjss8/w22+/VZvYRPL0njiuiaxcuZK5u7szpVLJAgIC2PHjx+usv2LFCtatWzdmZmbGOnTowGbPnl3zXIq1MKZ5LRljzMqqairGB6YvlKQ657WUiIfntXR1dWUfffSR3tvv27ePAWD//PMPY4wxU1NTtm3btkduB4Bt3769xnWurq7s448/FpT169ePhYeH6xXDgy5fvswAsNOnTz8ypqbWoua13Lx5MyIiIrBmzRoEBgYiNjYWISEhSE1NhaOjY7X6//3vfzF37lysX78e/fv3x5UrVzBp0iRwHIfly5eLcAQN12qmhJOghQsXYubMmbC1tUVoaCjKy8tx6tQp3L17FxEREVi+fDlcXFzg5+cHmUyGrVu3wtnZGXZ2dgCq7lzGx8djwIABUCqVsLe3r3VfaWlpSE5OFpR17doV77//PqKjo+Hp6QlfX1/ExcUhOTkZGzduBIA6Y9iwYQM0Gg0CAwNhYWGBH3/8Eebm5oLraC1GY2bZ+goICBD8z6LRaJirqyuLiYmpsX54eDh75plnBGURERFswIABeu/T2Fpkjo5VLbLzgVMYS0gQOxyDtcQWGWOMbdy4kfn6+jKFQsHs7e3ZU089xX755RfGGGNr165lvr6+zNLSktnY2LDBgwezM2fO8Nvu3LmTdenShZmYmDB3d/da9wugxuX3339nGo2GLViwgLVv356ZmpoyHx8ffnbyR8Wwfft2FhgYyGxsbJilpSV7/PHH2aFDhxrvA2uAxm6RiZbIysvLmVwur9aknjhxInv++edr3Gbjxo3M1taWP/28fv068/Lyqtb0flBZWRkrKCjgl8zMTKNKZB06VCWyU3iMsY0bxQ7HYC0hkZHm02JOLXNzc6HRaODk5CQod3JywuXLl2vc5pVXXkFubi6eeOIJMMagVqsxbdo0/Oc//6l1PzExMVi4cGGjxt6YaJRYQhpOUj37jxw5gsWLF+Orr77CmTNn8Msvv2D37t11Tn0VGRmJgoICftF1FjQWNAEJIQ0nWovMwcEBcrkc2dnZgvLs7OxaOxDOnz8fr776KqZMmQIA6N27N4qLizF16lTMmzcPMln1vKxUKqFUKhv/ABoJTUBCSMOJ1iJTKBTw9/dHfHw8X6bVahEfH4+goKAatykpKamWrHR9ephE5xmmuS0JaThRu19EREQgLCwMffv2RUBAAGJjY1FcXIzJkycDACZOnIj27dvzD8GOGDECy5cvh5+fHwIDA3Ht2jXMnz8fI0aMMPhZNrHxE5C0kBaZVP9DIc2rsX9PRE1k48ePx507dxAVFQWVSsU/2a+7AZCRkSFogX344YfgOA4ffvghbt26hXbt2mHEiBH4+OOPxTqEBuNbZDIzST+ipOspXlJSAnNzc5GjIcau5P5oyI31hAHHWtl/oYWFhbC1tUVBQQFsbGzEDgfPPAMkJAA//QTcfy5YsrKyspCfnw9HR0dYWFiA4zixQyJGhjGGkpIS5OTkwM7ODi4uLtXqGPI3Ss9aiow/tWwBl8d0N2lycnJEjoQYu4aOCvIwSmQia0mPKHEcBxcXFzg6OqKyJRwQaRKmpqaNfk2bEpnI+H5kX6wG7pUDs2eLGk9jkMvlkr35QqSJEpnI+H5k51OAU3niBkOIREmqZ39LRP3ICGk4SmQia2n9yAgRAyUykdFD44Q0HCUykelaZOVQ0qklIQaiRCYyXSf4MphRi4wQA1EiE5mZWdW/lMgIMRwlMpHpWmSlE6cBJ0+KGwwhEkX9yETGt8gq5QA9mkiIQahFJjK+RVYqbhyESBklMpHxLbLj54CpU8UNhhCJokQmMv6uZVYe8PPP4gZDiERRIhOZrkVWCnO6a0mIgSiRiUzQ/YI6xBJiEEpkIuMv9sO8alAyCQ93TYhYKJGJTNAiA6hVRogBKJGJTNAiA+g6GSEGoEQmMmqREdJw1LNfZHyLzMQayC8CLCzEDYgQCaIWmch0LTK1moNaaQnQFGqE1BslMpE9OJdtWZl4cRAiZZTIRKZrkQFA2ZS3gJs3RYuFEKmiRCYymezfUWJLN/8PoMltCak3SmRGgAZXJKRhKJEZAUFfMkpkhNQbJTIjQM9bEtIwlMiMAJ1aEtIwlMiMgODUklpkhNQbJTIjQC0yQhqGHlEyAnyLbM13wHjzuisTQqqhRGYE+BaZ0g5QihoKIZJEp5ZGgGZSIqRhRE9kq1atgoeHB8zMzBAYGIgTJ07UWT8/Px/h4eFwcXGBUqlEt27dsGfPnmaKtmnwLbKNPwN794obDCESJGoi27x5MyIiIhAdHY0zZ87Ax8cHISEhyKnlMZ2KigoMGTIEN2/exLZt25Camop169ahffv2zRx54+JbZImngUckckJIdaJeI1u+fDneeOMNTJ48GQCwZs0a7N69G+vXr8fcuXOr1V+/fj3y8vJw7NgxmJqaAgA8PDyaM+QmIbxrSUNgEFJforXIKioqcPr0aQQHB/8bjEyG4OBgJCUl1bjNzp07ERQUhPDwcDg5OaFXr15YvHgxNBpNrfspLy9HYWGhYDE29IgSIQ0jWiLLzc2FRqOBk5OToNzJyQkqlarGbW7cuIFt27ZBo9Fgz549mD9/PpYtW4b/+7//q3U/MTExsLW15Rc3N7dGPY7GQI8oEdIwol/srw+tVgtHR0esXbsW/v7+GD9+PObNm4c1a9bUuk1kZCQKCgr4JTMzsxkj1g+1yAhpGNGukTk4OEAulyM7O1tQnp2dDWdn5xq3cXFxgampKeRyOV/m7e0NlUqFiooKKHQDez1AqVRCqTTuzlnUs5+QhhGtRaZQKODv74/4+Hi+TKvVIj4+HkFBQTVuM2DAAFy7dg3aByaxvXLlClxcXGpMYlKhS2SlMKfOZIQYQNRTy4iICKxbtw7fffcdUlJSMH36dBQXF/N3MSdOnIjIyEi+/vTp05GXl4dZs2bhypUr2L17NxYvXozw8HCxDqFR6E4tywaFAnWcJhNCaiZq94vx48fjzp07iIqKgkqlgq+vL/bt28ffAMjIyIBM9m+udXNzw/79+/HOO++gT58+aN++PWbNmoU5c+aIdQiNgj+1lFkCbSzFDYYQCeIYY0zsIJpTYWEhbG1tUVBQABsbG7HDAQDs2AGMHg0EBQHHjokdDSHiMuRvVFJ3LVsqvkV24xaweLG4wRAiQZTIjADf/SK7EFi3TtxgCJEgSmRGQND9orhY3GAIkSBKZEZA0CGWEhkh9UaJzAgIWmQlJUDruv9CSIMZlMgyMzPx999/869PnDiB2bNnY+3atY0WWGsiaJEB1CmWkHoyKJG98sorSEhIAACoVCoMGTIEJ06cwLx58/DRRx81aoCtga5FVgEltODo9JKQejIokV28eBEBAQEAgC1btqBXr144duwYNm7ciA0bNjRmfK2C+QPzjfCnl4QQvRmUyCorK/kHsQ8dOoTnn38eAODl5YWsrKzGi66V0LXIAKDs+HnA1VW8YAiRIIMSWc+ePbFmzRr8/vvvOHjwIEJDQwEAt2/fRtu2bRs1wNbAxATQDehR2r4LcH/0W0KIfgxKZJ988gm+/vprDBo0CC+//DJ8fHwAVI3gqjvlJPXDPzhOI10TUm8GPTQ+aNAg5ObmorCwEPb29nz51KlTYWFh0WjBtSZmZkBREVC65HPgnSFAjx5ih0SIZBjUIistLUV5eTmfxNLT0xEbG4vU1FQ4Ojo2aoCtBd8i++YH4K+/xA2GEIkxKJGNHDkS33//PYCqeSYDAwOxbNkyjBo1CqtXr27UAFsLekyJEMMZlMjOnDmDJ598EgCwbds2ODk5IT09Hd9//z2++OKLRg2wtaDHlAgxnEGJrKSkBNbW1gCAAwcOYMyYMZDJZHj88ceRnp7eqAG2FtQiI8RwBiWyLl26YMeOHcjMzMT+/fvx7LPPAgBycnKMZrBCqRG0yKhDLCH1YlAii4qKwnvvvQcPDw8EBATwk4UcOHAAfn5+jRpga0EtMkIMZ1D3ixdeeAFPPPEEsrKy+D5kADB48GCMHj260YJrTegaGSGGM3jyEWdnZzg7O/OjYHTo0IE6wzYA3yJ790MgQl53ZUKIgEGnllqtFh999BFsbW3h7u4Od3d32NnZYdGiRYI5J4n++BaZgxs9a0lIPRnUIps3bx6+/fZbLFmyBAMGDAAA/PHHH1iwYAHKysrw8ccfN2qQrQHfIqNHlAipN4MS2XfffYdvvvmGH/UCAD/P5IwZMyiRGYCfbTzhT8DtL+D118UNiBAJMejUMi8vD15eXtXKvby8kJeX1+CgWiP+EaWjx2m2cULqyaBE5uPjg5UrV1YrX7lyJfr06dPgoFojvkVGdy0JqTeDTi0//fRTDB8+HIcOHeL7kCUlJSEzMxN79uxp1ABbC+oQS4jhDGqRDRw4EFeuXMHo0aORn5+P/Px8jBkzBn/99Rd++OGHxo6xVbCyqvq3CFbUIiOkngzuR+bq6lrtov65c+fw7bff0mxKBtA92VUIG0pkhNQTzWtpJASJrLQUoP54hOiNEpmRECQygK6TEVIPlMiMhC6R3WvrAZw4IZxaiRBSp3pdIxszZkyd6/Pz8xsSS6vGt8jKlEC/fuIGQ4jE1CuR2draPnL9xIkTGxRQa6VLZMXFgEbz7/RwhJBHq1cii4uLa6o4Wr37A+4CAO59/AXsXhsDdOggXkCESAhdIzMSSmXVAgCF0UuBq1fFDYgQCTGKRLZq1Sp4eHjAzMwMgYGBOHHihF7bbdq0CRzHYdSoUU0bYDMR3Lmku5aE6E30RLZ582ZEREQgOjoaZ86cgY+PD0JCQpCTk1Pndjdv3sR7773Hz+bUElCnWEIMI3oiW758Od544w1MnjwZPXr0wJo1a2BhYYH169fXuo1Go8GECROwcOFCdO7cuRmjbVqUyAgxjKiJrKKiAqdPn0ZwcDBfJpPJEBwcjKSkpFq3++ijj+Do6IjX9Rizq7y8HIWFhYLFWFEiI8Qwoiay3NxcaDQaODk5CcqdnJygUqlq3OaPP/7At99+i3Xr1um1j5iYGNja2vKLm5tbg+NuKnSNjBDDiH5qWR/37t3Dq6++inXr1sHBwUGvbSIjI1FQUMAvmZmZTRyl4ahFRohhDB79ojE4ODhALpcjOztbUJ6dnQ1nZ+dq9a9fv46bN29ixIgRfJlushMTExOkpqbC09NTsI1SqYRS16/ByOn6khVOfBt4TVL/xxAiKlH/WhQKBfz9/REfH8+XabVaxMfH8wM2PsjLywsXLlxAcnIyvzz//PN4+umnkZycbNSnjfrgW2RtOwHu7uIGQ4iEiNoiA4CIiAiEhYWhb9++CAgIQGxsLIqLizF58mQAwMSJE9G+fXvExMTAzMwMvXr1EmxvZ2cHANXKpYhPZMZ7P4IQoyR6Ihs/fjzu3LmDqKgoqFQq+Pr6Yt++ffwNgIyMDMhkreM0i09kZ68Dv14CHjiFJoTUjmOMMbGDaE6FhYWwtbVFQUEBbHSZw0h89x0waRIQgn3YF/o5sHev2CER0uwM+RttHU0dieDHJIM13bUkpB4okRkRQfcLulBGiN4okRkRQSKjiY4J0RslMiNCiYwQw1AiMyIPJjJWXAyUl4sbECESQYnMiOgSmRZylMCCWmWE6IkSmRGxsAB0XeYKtx4A7O3FDYgQiaBEZkQ47oHTy94DaEo4QvREiczI0GNKhNQfJTIjwyeyjb8C586JGwwhEkGJzMjwiezz9cChQ+IGQ4hEUCIzMvyYZNSXjBC9USIzMoJOsf/8I24whEgEJTIjQ737Cak/SmRGhhIZIfVHiczICIbyoURGiF4okRkZapERUn+UyIwMn8j6PgP88IO4wRAiEaKP2U+EdImswMIVeNJV3GAIkQhqkRmZtm2r/s3NFTcOQqSEEpmRcXGp+jcrowJYswa4c0fcgAiRAEpkRkY3wfrdIgXKps8GrlwRNR5CpIASmZGxtweUyqqfVXCmO5eE6IESmZHhuH9bZZTICNEPJTIjxF8ngws9b0mIHiiRGSFdiywLLtQiI0QPlMiMkKBFRomMkEeiRGaEdImMrpERoh/q2W+E+BaZ/3PA3H7iBkOIBFAiM0J8ImMugK+LuMEQIgF0ammE+Iv9WeLGQYhUUCIzQroWWU62FprlnwNarbgBEWLkKJEZIUdHgOMYNFoZct9dDKhUYodEiFGjRGaETEwAR0cOwP0uGGlpIkdEiHGjRGakBH3JbtwQNxhCjBwlMiMl6N1PLTJC6mQUiWzVqlXw8PCAmZkZAgMDceLEiVrrrlu3Dk8++STs7e1hb2+P4ODgOutLlaBTLCUyQuokeiLbvHkzIiIiEB0djTNnzsDHxwchISHIycmpsf6RI0fw8ssvIyEhAUlJSXBzc8Ozzz6LW7duNXPkTUtwakmJjJC6MZEFBASw8PBw/rVGo2Gurq4sJiZGr+3VajWztrZm3333nV71CwoKGABWUFBgULzN5csvGQMYG4utjLm5iR0OIc3GkL9RUVtkFRUVOH36NIKDg/kymUyG4OBgJCUl6fUeJSUlqKysRJs2bWpcX15ejsLCQsEiBfw1su6DgB07xAyFEKMnaiLLzc2FRqOBk5OToNzJyQkqPftOzZkzB66uroJk+KCYmBjY2tryi5ubW4Pjbg78qWWFA/DYY+IGQ4iRE/0aWUMsWbIEmzZtwvbt22FmZlZjncjISBQUFPBLZmZmM0dpmE6dqv7NyADKysSNhRBjJ2oic3BwgFwuR3Z2tqA8Ozsbzrpzq1osXboUS5YswYEDB9CnT59a6ymVStjY2AgWKXBxqZoaTqMB/pr3XyAxUeyQCDFaoiYyhUIBf39/xMfH82VarRbx8fEICgqqdbtPP/0UixYtwr59+9C3b9/mCLXZcRzg41P187nlh4CdO8UNiBAjJvqpZUREBNatW4fvvvsOKSkpmD59OoqLizF58mQAwMSJExEZGcnX/+STTzB//nysX78eHh4eUKlUUKlUKCoqEusQmgyfyOBDXTAIqYPo45GNHz8ed+7cQVRUFFQqFXx9fbFv3z7+BkBGRgZksn/z7erVq1FRUYEXXnhB8D7R0dFYsGBBc4be5Hx9q/5Nhi+Q9qOYoRBi1DjGGBM7iOZUWFgIW1tbFBQUGP31snPnqpKZLfJx194TXB7NqERaPkP+RkU/tSS18/YGTE0ZCmCHjLtWQC1POxDS2lEiM2IKBeDtXTWczzn4AAkJIkdEiHGiRGbkBBf8f/9d3GAIMVKUyIwcn8iefgeIjRU1FkKMleh3LUnd+ESW2Ya+LUJqQS0yI6dLZNeu0axKhNSGEpmRa9cO0D3k8P3In4EPPhA3IEKMECUyCZgyperfb072AfvhR6B1df0j5JEokUnAuHGAlRXDNXTFUVVXQM+x2ghpLSiRSYCVFfDKK1X9yb7BFCAyklplhDyAEplE6E4vt+EF3Dp6Ddi1S9yACDEilMgkom9fICAAKIM5xmMzKj+YB6jVYodFiFGgRCYRHAf8+CNgY82QiCfw/uXXgM2bxQ6LEKNAiUxCunYFvv+h6lrZ55iNyYdewd27IgdFiBGgRCYxI0cCS5ZUtdA2bODQowfwxcK7KP7iWzrVJK0WjUcmUceOAa+9BqSmVr1ug38wzfq/mPGWDO3fGVfVk5YQCaLxyFqR/v2B5GRg9VcMng75yENbLL73NjxipuIlp8NIeDwS7MeNQH6+2KES0uSoRdYCaDTAzm0ViI3Ow9HUf2efao+/MbTNcYSuHYtnngHs7VHV/4zjxAuWkEcw5G+UElkLk5wMfL3kLn7cboGiCiVfLpMBvXpo4HXlV/ToWIR+ARwCnnOEw8CeVXPPUXIjRoISmR5aeiLTKS0Fjh4F9u7W4MAhOVJSaq7ngDvwMrmGHg530CukPTzH+cPdHejQrhw26jxwTo6AXN68wZNWjRKZHlpLInvYrVvA2VMaXDlyG+eOFeH4ZVukFrrWuY0ZSuGCLDib5sHZogDtrErR1kYNa2vA6vGeMO/dFWZmgJWmAFZXzsDc2gRm1iZQWJjC1NwEpuZyKCxMAScnqK3tIZMB1soKmBfnQsOZQAsZTBRVC+RyaCGDwkoBmdK0KgDGAK22qrWoW0iLR4lMD601kdWkuBi4cr4MKYez8NfJYvxV3Ak371giPV3cewRKZVXO0qi1gi4lDBw4MJhADTk0UJuYQQ1TyGSAXKaFoqwQppwaDBwqmSlMODXMUQYFVwHOxhpo0xYaDQCNBiZZGZBDCwYO4AA5NJBzWsigBezswLm4VD3OqtWAXb3GxyDjGEw5NUyggRYyMFs7yD3cYGICcGDgks+ijClQojWDDAxW8hKYcmqomQlgawOTLp0gl1cdHzt9BoyxqhhQlaQ5jkEGBpmtFWRe3aGbCZE7cwommgrIOS04rmob3XacjRW4Pn34PM9OngKrqHjoU61aKbcyh+wxX8hkVTHITp8EV1p8/72q6sk4BnAAMzMH6xsAxqr+T2HJ58AVF8FEpoGcY4K35hQKyJ8I4hvv7PQZaPMLoWGyf9/b1xdz/s8a3t51f/+UyPRAiUw/JSWA6m81VCl3kZVaiOz0MuSqKvHPHYZ794AiB3eUW7RBSQlQnF2EohvZKFUrUKpVoFIrRyUzQSUzQQUzBUxMYKKQQ6MBysvFPjIipoQEYNCguusY8jdKgyeTGllYAJ27maBzt3YAHtUnzer+8miVlUBZWdVlNxm0UFdULRzTgtNqUK41RalGAcYAOVODK7oHaLVgGi04MDCNFpWVgEbNYGpnCZM2NtBqAU1ZJSozslBRUfW+JjIt1OqqhFyp5sCsrMHaOlS1hjRqaK7egFpd1YpiDNBqGNTq+4OK2NpW3QABwGk1QEoKOFQ1SzSaqmNQq6taZ5y9LbRuHqisBJhGC3buPJSmWlgo1NBqgeIyOSrVHOQyBtjaQtOpS1WrEABOnbrfrrrf5AEDYxy0WoBZ20DTzZsf5ERz/BQ0lRpoNFWtG8bu7x8MzNIKGu9e/5afPQ2usoIfIYUxXZuIQWNmBW0fX/6snZ05C21JKd8e07W+OI4BSjNwff3/PbM/ewbsXhE0Wg5qLce/J2MctCYKaPsG8MfGXTgPWVEh5DJW1coFAD8/dO7cNI0HapERQowKdYglhLRKlMgIIZJHiYwQInmUyAghkkeJjBAieZTICCGSR4mMECJ5lMgIIZJHiYwQInmUyAghkmcUiWzVqlXw8PCAmZkZAgMDceLEiTrrb926FV5eXjAzM0Pv3r2xZ8+eZoqUEGKMRE9kmzdvRkREBKKjo3HmzBn4+PggJCQEOTk5NdY/duwYXn75Zbz++us4e/YsRo0ahVGjRuHixYvNHDkhxFiI/tB4YGAg+vXrh5UrVwIAtFot3Nzc8Pbbb2Pu3LnV6o8fPx7FxcXYtWsXX/b444/D19cXa9aseeT+6KFxQoyb5IbxqaiowOnTpxEZGcmXyWQyBAcHIykpqcZtkpKSEBERISgLCQnBjh07aqxfXl6O8gcGwSooKABQ9WERQoyP7m+zPm0sURNZbm4uNBoNnJycBOVOTk64fPlyjduoVKoa66tUqhrrx8TEYOHChdXK3dzcDIyaENIc7t27B1tbW73qtviBFSMjIwUtOK1Wi7y8PLRt2xZcLWPAFxYWws3NDZmZmS3m9JOOSTpa4nHV55gYY7h37x5cXeueU+JBoiYyBwcHyOVyZGdnC8qzs7Ph7Oxc4zbOzs71qq9UKqFUKgVldnZ2esVnY2PTYn6RdOiYpKMlHpe+x6RvS0xH1LuWCoUC/v7+iI+P58u0Wi3i4+MRFBRU4zZBQUGC+gBw8ODBWusTQlo+0U8tIyIiEBYWhr59+yIgIACxsbEoLi7G5MmTAQATJ05E+/btERMTAwCYNWsWBg4ciGXLlmH48OHYtGkTTp06hbVr14p5GIQQEYmeyMaPH487d+4gKioKKpUKvr6+2LdvH39BPyMjAzLZvw3H/v3747///S8+/PBD/Oc//0HXrl2xY8cO9OrVq9FiUiqViI6OrnZKKmV0TNLREo+rqY9J9H5khBDSUKL37CeEkIaiREYIkTxKZIQQyaNERgiRPEpkD6nvkELGJCYmBv369YO1tTUcHR0xatQopKamCuoMGjQIHMcJlmnTpokUsX4WLFhQLWYvLy9+fVlZGcLDw9G2bVtYWVlh7Nix1TpNGxsPD49qx8RxHMLDwwFI53s6evQoRowYAVdXV3AcV+2ZZ8YYoqKi4OLiAnNzcwQHB+Pq1auCOnl5eZgwYQJsbGxgZ2eH119/HUVFRfWKgxLZA+o7pJCx+e233xAeHo4///wTBw8eRGVlJZ599lkUFxcL6r3xxhvIysril08//VSkiPXXs2dPQcx//PEHv+6dd97Br7/+iq1bt+K3337D7du3MWbMGBGjfbSTJ08KjufgwYMAgBdffJGvI4Xvqbi4GD4+Pli1alWN6z/99FN88cUXWLNmDY4fPw5LS0uEhISgrKyMrzNhwgT89ddfOHjwIHbt2oWjR49i6tSp9QuEEV5AQAALDw/nX2s0Gubq6spiYmJEjMpwOTk5DAD77bff+LKBAweyWbNmiReUAaKjo5mPj0+N6/Lz85mpqSnbunUrX5aSksIAsKSkpGaKsOFmzZrFPD09mVarZYxJ83sCwLZv386/1mq1zNnZmX322Wd8WX5+PlMqleynn35ijDF26dIlBoCdPHmSr7N3717GcRy7deuW3vumFtl9uiGFgoOD+bJHDSlk7HRDFrVp00ZQvnHjRjg4OKBXr16IjIxESUmJGOHVy9WrV+Hq6orOnTtjwoQJyMjIAACcPn0alZWVgu/Ny8sLHTt2lMz3VlFRgR9//BGvvfaaYCADKX5PD0pLS4NKpRJ8N7a2tggMDOS/m6SkJNjZ2aFv3758neDgYMhkMhw/flzvfYnes99YGDKkkDHTarWYPXs2BgwYIHjq4ZVXXoG7uztcXV1x/vx5zJkzB6mpqfjll19EjLZugYGB2LBhA7p3746srCwsXLgQTz75JC5evAiVSgWFQlFtIIC6hnYyNjt27EB+fj4mTZrEl0nxe3qY7vOva9gtlUoFR0dHwXoTExO0adOmXt8fJbIWKjw8HBcvXhRcSwIguPbQu3dvuLi4YPDgwbh+/To8PT2bO0y9DB06lP+5T58+CAwMhLu7O7Zs2QJzc3MRI2sc3377LYYOHSoYtkaK35OY6NTyPkOGFDJWb731Fnbt2oWEhAR06NChzrqBgYEAgGvXrjVHaI3Czs4O3bp1w7Vr1+Ds7IyKigrk5+cL6kjle0tPT8ehQ4cwZcqUOutJ8XvSff51/U05OztXu5mmVquRl5dXr++PEtl9hgwpZGwYY3jrrbewfft2HD58GJ06dXrkNsnJyQAAFxeXJo6u8RQVFeH69etwcXGBv78/TE1NBd9bamoqMjIyJPG9xcXFwdHREcOHD6+znhS/p06dOsHZ2Vnw3RQWFuL48eP8dxMUFIT8/HycPn2ar3P48GFotVo+eeulwbcqWpBNmzYxpVLJNmzYwC5dusSmTp3K7OzsmEqlEjs0vUyfPp3Z2tqyI0eOsKysLH4pKSlhjDF27do19tFHH7FTp06xtLQ09r///Y917tyZPfXUUyJHXrd3332XHTlyhKWlpbHExEQWHBzMHBwcWE5ODmOMsWnTprGOHTuyw4cPs1OnTrGgoCAWFBQkctSPptFoWMeOHdmcOXME5VL6nu7du8fOnj3Lzp49ywCw5cuXs7Nnz7L09HTGGGNLlixhdnZ27H//+x87f/48GzlyJOvUqRMrLS3l3yM0NJT5+fmx48ePsz/++IN17dqVvfzyy/WKgxLZQ7788kvWsWNHplAoWEBAAPvzzz/FDklvAGpc4uLiGGOMZWRksKeeeoq1adOGKZVK1qVLF/b++++zgoICcQN/hPHjxzMXFxemUChY+/bt2fjx49m1a9f49aWlpWzGjBnM3t6eWVhYsNGjR7OsrCwRI9bP/v37GQCWmpoqKJfS95SQkFDj71xYWBhjrKoLxvz585mTkxNTKpVs8ODB1Y73n3/+YS+//DKzsrJiNjY2bPLkyezevXv1ioOG8SGESB5dIyOESB4lMkKI5FEiI4RIHiUyQojkUSIjhEgeJTJCiORRIiOESB4lMkKI5FEiI61WTUMzE2miREZEMWnSpBrHrA8NDRU7NCJBNB4ZEU1oaCji4uIEZUqlUqRoiJRRi4yIRqlUwtnZWbDY29sDqDrtW716NYYOHQpzc3N07twZ27ZtE2x/4cIFPPPMMzA3N0fbtm0xderUarPvrF+/Hj179oRSqYSLiwveeustwfrc3FyMHj0aFhYW6Nq1K3bu3Nm0B02aBCUyYrTmz5+PsWPH4ty5c5gwYQJeeuklpKSkAKiavSckJAT29vY4efIktm7dikOHDgkS1erVqxEeHo6pU6fiwoUL2LlzJ7p06SLYx8KFCzFu3DicP38ew4YNw4QJE5CXl9esx0kaQeMM5kFI/YSFhTG5XM4sLS0Fy8cff8wYqxqSaNq0aYJtAgMD2fTp0xljjK1du5bZ29uzoqIifv3u3buZTCbjx49zdXVl8+bNqzUGAOzDDz/kXxcVFTEAbO/evY12nKR50DUyIpqnn34aq1evFpQ9OOPTwyO8BgUF8SOlpqSkwMfHB5aWlvz6AQMGQKvVIjU1FRzH4fbt2xg8eHCdMfTp04f/2dLSEjY2NpKZx5T8ixIZEY2lpWW1U73Gou+kJKampoLXHMdBq9U2RUikCdE1MmK0/vzzz2qvvb29AQDe3t44d+6cYBb1xMREyGQydO/eHdbW1vDw8BCMF09aLmqREdGUl5dXm7vQxMQEDg4OAICtW7eib9++eOKJJ7Bx40acOHEC3377LQBgwoQJiI6ORlhYGBYsWIA7d+7g7bffxquvvsrPo7hgwQJMmzYNjo6OGDp0KO7du4fExES8/fbbzXugpMlRIiOi2bdvX7VZgbp3785PiLxw4UJs2rQJM2bMgIuLC3766Sf06NEDAGBhYYH9+/dj1qxZ6NevHywsLDB27FgsX76cf6+wsDCUlZVhxYoVeO+99+Dg4IAXXnih+Q6QNBsas58YJY7jsH37dowaNUrsUIgE0DUyQojkUSIjhEgeXSMjRomueJD6oBYZIUTyKJERQiSPEhkhRPIokRFCJI8SGSFE8iiREUIkjxIZIUTyKJERQiTv/wPfXerTD0+IxwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with replicate 1 heldout. # samples = 78421\n",
      "HI\n",
      "Epoch 1/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 50.7174 - mse: 2.0601 - mae: 1.1254 - val_loss: 44.5768 - val_mse: 0.9640 - val_mae: 0.7853\n",
      "Epoch 2/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 40.7065 - mse: 1.4818 - mae: 0.9395 - val_loss: 36.0594 - val_mse: 0.9734 - val_mae: 0.7468\n",
      "Epoch 3/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 32.2908 - mse: 0.8425 - mae: 0.7084 - val_loss: 28.5223 - val_mse: 0.5407 - val_mae: 0.5868\n",
      "Epoch 4/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 25.4402 - mse: 0.5307 - mae: 0.5800 - val_loss: 22.3695 - val_mse: 0.3771 - val_mae: 0.5036\n",
      "Epoch 5/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 19.8339 - mse: 0.3970 - mae: 0.5111 - val_loss: 17.3309 - val_mse: 0.3064 - val_mae: 0.4593\n",
      "Epoch 6/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 15.2616 - mse: 0.3279 - mae: 0.4693 - val_loss: 13.2382 - val_mse: 0.2681 - val_mae: 0.4313\n",
      "Epoch 7/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 11.5673 - mse: 0.2825 - mae: 0.4380 - val_loss: 9.9505 - val_mse: 0.2407 - val_mae: 0.4084\n",
      "Epoch 8/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 8.6204 - mse: 0.2484 - mae: 0.4116 - val_loss: 7.3471 - val_mse: 0.2187 - val_mae: 0.3883\n",
      "Epoch 9/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 6.3054 - mse: 0.2210 - mae: 0.3882 - val_loss: 5.3193 - val_mse: 0.1994 - val_mae: 0.3697\n",
      "Epoch 10/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 4.5190 - mse: 0.1981 - mae: 0.3670 - val_loss: 3.7705 - val_mse: 0.1823 - val_mae: 0.3525\n",
      "Epoch 11/100\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 3.1689 - mse: 0.1785 - mae: 0.3479 - val_loss: 2.6134 - val_mse: 0.1669 - val_mae: 0.3365\n",
      "Epoch 12/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 2.1722 - mse: 0.1618 - mae: 0.3308 - val_loss: 1.7705 - val_mse: 0.1532 - val_mae: 0.3222\n",
      "Epoch 13/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 1.4552 - mse: 0.1471 - mae: 0.3154 - val_loss: 1.1727 - val_mse: 0.1407 - val_mae: 0.3088\n",
      "Epoch 14/100\n",
      "252/491 [==============>...............] - ETA: 1s - loss: 1.0534 - mse: 0.1372 - mae: 0.3047\n",
      "Epoch 14: saving model to ./saved-weights/cross-validation-3HB/holdout-1/checkpoint\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.9538 - mse: 0.1343 - mae: 0.3014 - val_loss: 0.7613 - val_mse: 0.1291 - val_mae: 0.2961\n",
      "Epoch 15/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.6159 - mse: 0.1235 - mae: 0.2894 - val_loss: 0.4895 - val_mse: 0.1183 - val_mae: 0.2836\n",
      "Epoch 16/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.3979 - mse: 0.1148 - mae: 0.2793 - val_loss: 0.3192 - val_mse: 0.1113 - val_mae: 0.2753\n",
      "Epoch 17/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.2628 - mse: 0.1073 - mae: 0.2703 - val_loss: 0.2160 - val_mse: 0.1041 - val_mae: 0.2667\n",
      "Epoch 18/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.1840 - mse: 0.1009 - mae: 0.2626 - val_loss: 0.1581 - val_mse: 0.0981 - val_mae: 0.2592\n",
      "Epoch 19/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.1413 - mse: 0.0957 - mae: 0.2562 - val_loss: 0.1275 - val_mse: 0.0931 - val_mae: 0.2529\n",
      "Epoch 20/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.1195 - mse: 0.0916 - mae: 0.2510 - val_loss: 0.1136 - val_mse: 0.0906 - val_mae: 0.2499\n",
      "Epoch 21/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.1084 - mse: 0.0881 - mae: 0.2467 - val_loss: 0.1045 - val_mse: 0.0864 - val_mae: 0.2445\n",
      "Epoch 22/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.1020 - mse: 0.0852 - mae: 0.2431 - val_loss: 0.0995 - val_mse: 0.0840 - val_mae: 0.2416\n",
      "Epoch 23/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0976 - mse: 0.0829 - mae: 0.2401 - val_loss: 0.0949 - val_mse: 0.0809 - val_mae: 0.2374\n",
      "Epoch 24/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0941 - mse: 0.0808 - mae: 0.2375 - val_loss: 0.0930 - val_mse: 0.0804 - val_mae: 0.2372\n",
      "Epoch 25/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0911 - mse: 0.0791 - mae: 0.2353 - val_loss: 0.0901 - val_mse: 0.0787 - val_mae: 0.2349\n",
      "Epoch 26/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0885 - mse: 0.0776 - mae: 0.2334 - val_loss: 0.0873 - val_mse: 0.0769 - val_mae: 0.2322\n",
      "Epoch 27/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0862 - mse: 0.0764 - mae: 0.2318 - val_loss: 0.0851 - val_mse: 0.0757 - val_mae: 0.2308\n",
      "Epoch 28/100\n",
      " 22/491 [>.............................] - ETA: 2s - loss: 0.0850 - mse: 0.0757 - mae: 0.2308\n",
      "Epoch 28: saving model to ./saved-weights/cross-validation-3HB/holdout-1/checkpoint\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0842 - mse: 0.0753 - mae: 0.2304 - val_loss: 0.0830 - val_mse: 0.0745 - val_mae: 0.2292\n",
      "Epoch 29/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0824 - mse: 0.0744 - mae: 0.2292 - val_loss: 0.0811 - val_mse: 0.0734 - val_mae: 0.2274\n",
      "Epoch 30/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0809 - mse: 0.0736 - mae: 0.2282 - val_loss: 0.0802 - val_mse: 0.0733 - val_mae: 0.2278\n",
      "Epoch 31/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0795 - mse: 0.0729 - mae: 0.2273 - val_loss: 0.0790 - val_mse: 0.0727 - val_mae: 0.2274\n",
      "Epoch 32/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0783 - mse: 0.0724 - mae: 0.2265 - val_loss: 0.0777 - val_mse: 0.0721 - val_mae: 0.2260\n",
      "Epoch 33/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0773 - mse: 0.0719 - mae: 0.2259 - val_loss: 0.0766 - val_mse: 0.0715 - val_mae: 0.2253\n",
      "Epoch 34/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0765 - mse: 0.0715 - mae: 0.2253 - val_loss: 0.0761 - val_mse: 0.0714 - val_mae: 0.2251\n",
      "Epoch 35/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0757 - mse: 0.0712 - mae: 0.2249 - val_loss: 0.0755 - val_mse: 0.0712 - val_mae: 0.2251\n",
      "Epoch 36/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0751 - mse: 0.0710 - mae: 0.2245 - val_loss: 0.0745 - val_mse: 0.0706 - val_mae: 0.2234\n",
      "Epoch 37/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0746 - mse: 0.0708 - mae: 0.2241 - val_loss: 0.0744 - val_mse: 0.0707 - val_mae: 0.2242\n",
      "Epoch 38/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0742 - mse: 0.0706 - mae: 0.2239 - val_loss: 0.0738 - val_mse: 0.0703 - val_mae: 0.2232\n",
      "Epoch 39/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0738 - mse: 0.0705 - mae: 0.2237 - val_loss: 0.0735 - val_mse: 0.0702 - val_mae: 0.2229\n",
      "Epoch 40/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0736 - mse: 0.0703 - mae: 0.2235 - val_loss: 0.0736 - val_mse: 0.0705 - val_mae: 0.2239\n",
      "Epoch 41/100\n",
      "274/491 [===============>..............] - ETA: 1s - loss: 0.0734 - mse: 0.0703 - mae: 0.2233\n",
      "Epoch 41: saving model to ./saved-weights/cross-validation-3HB/holdout-1/checkpoint\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0734 - mse: 0.0703 - mae: 0.2233 - val_loss: 0.0731 - val_mse: 0.0700 - val_mae: 0.2227\n",
      "Epoch 42/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0732 - mse: 0.0702 - mae: 0.2232 - val_loss: 0.0730 - val_mse: 0.0700 - val_mae: 0.2227\n",
      "Epoch 43/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0730 - mse: 0.0701 - mae: 0.2230 - val_loss: 0.0728 - val_mse: 0.0700 - val_mae: 0.2225\n",
      "Epoch 44/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0729 - mse: 0.0701 - mae: 0.2229 - val_loss: 0.0728 - val_mse: 0.0699 - val_mae: 0.2224\n",
      "Epoch 45/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0728 - mse: 0.0700 - mae: 0.2228 - val_loss: 0.0728 - val_mse: 0.0701 - val_mae: 0.2231\n",
      "Epoch 46/100\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.0727 - mse: 0.0700 - mae: 0.2227 - val_loss: 0.0727 - val_mse: 0.0700 - val_mae: 0.2229\n",
      "Epoch 47/100\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 0.0727 - mse: 0.0700 - mae: 0.2227 - val_loss: 0.0725 - val_mse: 0.0697 - val_mae: 0.2217\n",
      "Epoch 48/100\n",
      "232/491 [=============>................] - ETA: 1s - loss: 0.0726 - mse: 0.0699 - mae: 0.2225"
     ]
    }
   ],
   "source": [
    "Brain_3HB_IsoLearner.cross_validation_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
